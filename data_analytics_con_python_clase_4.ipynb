{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vhcontre/data-analytics-con-python/blob/main/data_analytics_con_python_clase_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üêç V√≠ctor H\n",
        "\n",
        "Hola! Soy Victor, y me encanta aprender Data Analytics con Python. Aqu√≠ van algunas cosas sobre m√≠:\n",
        "\n",
        "**Fortalezas:**\n",
        "- Trabajo en proyectos de software\n",
        "- Me gusta aprender cosas nuevas\n",
        "- Disfruto organizar y planificar\n",
        "\n",
        "*Recuerden siempre*: la pr√°ctica hace al maestro.\n",
        "\n",
        "Documentaci√≥n oficial de Python: [Python Docs](https://docs.python.org/3/)\n",
        "\n",
        "\n",
        "> ‚ÄúEl conocimiento es poder, pero la sabidur√≠a es aplicarlo.‚Äù\n"
      ],
      "metadata": {
        "id": "XcUr3vbtvq3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ¬©Ô∏è Clase 4 - Calidad de Datos\n",
        "\n",
        "## DATA ANALYTICS - Calidad de Datos\n",
        "\n",
        "---\n",
        "\n",
        "## √çndice\n",
        "\n",
        "- Obtenci√≥n y limpieza de datos en Python  \n",
        "- Concepto de calidad de los datos y su importancia  \n",
        "- Identificaci√≥n y tratamiento de valores nulos y duplicados  \n",
        "- Limpieza de Datos con Pandas  \n",
        "- Los desaf√≠os de la raw data  \n",
        "- T√©cnicas para limpiar datos: eliminaci√≥n de duplicados, caracteres no deseados, correcci√≥n en los tipos de datos  \n",
        "\n",
        "---\n",
        "\n",
        "## Objetivos de la Clase\n",
        "\n",
        "- Conocer los conceptos principales de la calidad de datos y su importancia en la anal√≠tica de datos  \n",
        "- Aprender a identificar valores nulos y duplicados, y considerar estrategias para tratarlos  \n",
        "\n",
        "---\n",
        "\n",
        "## Introducci√≥n a la Calidad de los Datos\n",
        "\n",
        "La **calidad de datos** es la medida de la adecuaci√≥n de un conjunto de datos para un prop√≥sito espec√≠fico.\n",
        "\n",
        "### Atributos clave\n",
        "\n",
        "- Precisi√≥n  \n",
        "- Completitud  \n",
        "- Consistencia  \n",
        "- Validez  \n",
        "- Relevancia  \n",
        "\n",
        "### Importancia\n",
        "\n",
        "- Fundamento de an√°lisis precisos y decisiones informadas  \n",
        "- Ejemplo: decisiones err√≥neas en lanzamientos de productos debido a datos inexactos pueden llevar a p√©rdidas significativas  \n",
        "\n",
        "---\n",
        "\n",
        "## Evaluaci√≥n de la Calidad de los Datos en Python\n",
        "\n",
        "Usar la biblioteca **Pandas** para analizar calidad:  \n",
        "\n",
        "```python\n",
        "df.info()       # Resumen del DataFrame\n",
        "df.isnull().sum()  # Contar valores nulos\n",
        "````\n",
        "\n",
        "---\n",
        "\n",
        "## Identificaci√≥n y Tratamiento de Valores Nulos\n",
        "\n",
        "* Valores nulos: representan la ausencia de informaci√≥n\n",
        "* Problemas: dificultan an√°lisis estad√≠sticos y modelos predictivos\n",
        "\n",
        "### Estrategias\n",
        "\n",
        "* Eliminaci√≥n\n",
        "* Imputaci√≥n: rellenar con media, mediana o moda\n",
        "* Predicci√≥n: modelos predictivos para estimar valores faltantes\n",
        "\n",
        "---\n",
        "\n",
        "## Identificaci√≥n y Tratamiento de Duplicados\n",
        "\n",
        "* Duplicados: registros repetidos en conjuntos de datos\n",
        "* Problemas: inflan resultados y distorsionan an√°lisis\n",
        "\n",
        "### Estrategias\n",
        "\n",
        "* Identificaci√≥n\n",
        "* Eliminaci√≥n\n",
        "\n",
        "---\n",
        "\n",
        "## Reflexi√≥n Final\n",
        "\n",
        "* La calidad de los datos es esencial para un an√°lisis efectivo\n",
        "* El manejo adecuado de valores nulos y duplicados asegura resultados precisos\n",
        "* Implementar buenas pr√°cticas en Python mejora la fiabilidad y relevancia de los an√°lisis\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öôÔ∏è Ejercicios Pr√°cticos\n",
        "\n",
        "### Actividad 1: Identificaci√≥n de Valores Nulos y Duplicados\n",
        "\n",
        "**Objetivos:**\n",
        "\n",
        "* Practicar la carga de datos en un DataFrame usando Pandas\n",
        "* Identificar y contar valores nulos en diferentes columnas\n",
        "* Detectar y contar registros duplicados\n",
        "* Generar un informe que resuma los hallazgos de la limpieza\n",
        "\n",
        "**Contexto:**\n",
        "Mentor: Mat√≠as\n",
        "Tu tarea: cargar datos en un DataFrame y aplicar m√©todos para identificar filas con datos faltantes y duplicados\n",
        "\n",
        "**Consigna:**\n",
        "\n",
        "* Descargar los datos en CSV y cargarlos en un DataFrame con Pandas\n",
        "* Usar `isnull()` para identificar y contar valores nulos\n",
        "* Usar `duplicated()` para identificar y contar registros duplicados\n",
        "* Crear un informe que incluya:\n",
        "\n",
        "  * Total de registros\n",
        "  * Valores nulos por columna\n",
        "  * N√∫mero de filas duplicadas\n",
        "  * DataFrame con registros duplicados\n",
        "\n",
        "**Datos:** `satis_clientes`\n",
        "\n",
        "**Importancia en SynthData:**\n",
        "Datos limpios y precisos permiten tomar decisiones inteligentes y generar informes confiables\n",
        "\n",
        "---\n",
        "\n",
        "### Actividad 2: Exploraci√≥n y limpieza preliminar con Python\n",
        "\n",
        "**Objetivos:**\n",
        "\n",
        "* Identificar datos duplicados y nulos\n",
        "* Analizar el mejor tratamiento para datos an√≥malos y nulos\n",
        "\n",
        "**Contexto:**\n",
        "Mentor: Luis (Analista de BI)\n",
        "Trabajar√°s con una planilla de Google Sheets que registra temperaturas corporales durante 10 d√≠as\n",
        "\n",
        "**Consigna:**\n",
        "\n",
        "* Crear un DataFrame a partir de la planilla\n",
        "* Identificar datos duplicados y nulos\n",
        "* Analizar el mejor tratamiento para valores an√≥malos y nulos\n",
        "\n",
        "**Importancia en SynthData:**\n",
        "La exploraci√≥n y limpieza de datos asegura que los an√°lisis sean robustos y significativos\n",
        "\n",
        "---\n",
        "\n",
        "### Notas finales\n",
        "\n",
        "* Los ejercicios son simulaciones; las soluciones dependen del contexto, los datasets y los requerimientos espec√≠ficos\n",
        "* üìÑ ¬°Nuevo cuestionario en Campus! (obligatorio para avanzar en la cursada)\n",
        "\n"
      ],
      "metadata": {
        "id": "o0OQ3pMEkYPc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Actividad 1: Identificaci√≥n de Valores Nulos y Duplicados\n",
        "\n",
        "**Objetivo:**  \n",
        "Descargar los datos en formato CSV y cargarlos en un DataFrame en Python usando **Pandas**.  \n",
        "\n",
        "**Pasos a realizar:**\n",
        "\n",
        "1. Utilizar el m√©todo `isnull()` para identificar las filas con datos faltantes y contar el n√∫mero de valores nulos por columna.  \n",
        "2. Usar el m√©todo `duplicated()` para identificar las filas duplicadas y contar cu√°ntas filas duplicadas hay en total.  \n",
        "3. Crear un informe que incluya:  \n",
        "   - La cantidad total de registros en el DataFrame.  \n",
        "   - La cantidad total de valores nulos por columna.  \n",
        "   - La cantidad de filas duplicadas.  \n",
        "   - Crear un DataFrame de los registros duplicados para visualizar su contenido.  \n",
        "\n",
        "**Datos a utilizar:** `satis_clientes`  \n",
        "\n",
        "**Importancia en SynthData:**  \n",
        "La identificaci√≥n de valores nulos y duplicados es vital en el trabajo de an√°lisis de datos. En SynthData, utilizamos datos limpios y precisos para tomar decisiones inteligentes. Aprender a reconocer estos problemas en los datos permitir√° brindar un gran apoyo al equipo en la generaci√≥n de informes y an√°lisis m√°s confiables.\n"
      ],
      "metadata": {
        "id": "BXieXM2Yrb1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# ===============================\n",
        "# Funci√≥n: Subir CSV desde PC\n",
        "# ===============================\n",
        "def subir_csv_local():\n",
        "    \"\"\"\n",
        "    Hola, soy tu funci√≥n para cargar un CSV desde tu computadora.\n",
        "\n",
        "    Lo que hago:\n",
        "    1. Te permite seleccionar un archivo CSV desde tu PC.\n",
        "    2. Lo leo con Pandas y lo devuelvo listo para usar.\n",
        "\n",
        "    Retorna:\n",
        "    str : Nombre del archivo CSV subido\n",
        "    \"\"\"\n",
        "    uploaded = files.upload()  # Esto abre el selector de archivos\n",
        "    nombre_csv = list(uploaded.keys())[0]\n",
        "    print(f\"Archivo cargado: {nombre_csv}\")\n",
        "    return nombre_csv\n",
        "\n",
        "# ===============================\n",
        "# Ejemplo de uso integrando la funci√≥n existente\n",
        "# ===============================\n",
        "# Primero subo el archivo\n",
        "archivo_local = subir_csv_local()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6wG91ss6BkEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ===============================\n",
        "# Funci√≥n: Actividad 1 - Valores Nulos y Duplicados\n",
        "# ===============================\n",
        "def analizar_nulos_duplicados(nombre_csv):\n",
        "    \"\"\"\n",
        "    Funci√≥n para revisar valores nulos y duplicados.\n",
        "\n",
        "    Lo que hago:\n",
        "    1. Cargo el CSV en un DataFrame.\n",
        "    2. Identifico y cuento los valores nulos por columna.\n",
        "    3. Identifico y cuento filas duplicadas.\n",
        "    4. Creo un informe resumido y un DataFrame con los duplicados.\n",
        "\n",
        "    Par√°metros:\n",
        "    nombre_csv : str : Ruta o URL del archivo CSV a analizar.\n",
        "\n",
        "    Retorna:\n",
        "    dict : Un diccionario con:\n",
        "        - 'df': DataFrame original cargado.\n",
        "        - 'nulos': Serie con la cantidad de valores nulos por columna.\n",
        "        - 'duplicados_count': N√∫mero total de filas duplicadas.\n",
        "        - 'duplicados_df': DataFrame con las filas duplicadas.\n",
        "    \"\"\"\n",
        "    # Cargo el CSV\n",
        "    df = pd.read_csv(nombre_csv)\n",
        "\n",
        "    # Identifico valores nulos\n",
        "    nulos = df.isnull().sum()\n",
        "\n",
        "    # Identifico duplicados\n",
        "    duplicados_df = df[df.duplicated()]\n",
        "    duplicados_count = len(duplicados_df)\n",
        "\n",
        "    # Informe resumido\n",
        "    print(\"===== Informe de Calidad de Datos =====\")\n",
        "    print(f\"Total de registros: {len(df)}\")\n",
        "    print(\"\\nValores nulos por columna:\")\n",
        "    print(nulos)\n",
        "    print(f\"\\nTotal de filas duplicadas: {duplicados_count}\")\n",
        "    if duplicados_count > 0:\n",
        "        print(\"\\nEjemplo de filas duplicadas:\")\n",
        "        display(duplicados_df.head())\n",
        "    print(\"======================================\")\n",
        "\n",
        "    return {\n",
        "        'df': df,\n",
        "        'nulos': nulos,\n",
        "        'duplicados_count': duplicados_count,\n",
        "        'duplicados_df': duplicados_df\n",
        "    }\n",
        "\n",
        "# ===============================\n",
        "# Ejemplo de uso\n",
        "# ===============================\n",
        "# resultados = analizar_nulos_duplicados('ruta_o_url_del_csv/satis_clientes.csv')\n",
        "resultados = analizar_nulos_duplicados(archivo_local)\n"
      ],
      "metadata": {
        "id": "pktNgSpaBGrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Actividad 2: Exploraci√≥n y limpieza preliminar con Python\n",
        "\n",
        "### Objetivos\n",
        "- Identificar los datos duplicados y nulos en el conjunto.\n",
        "- Analizar el mejor tratamiento para los datos an√≥malos y nulos.\n",
        "\n",
        "### Contexto\n",
        "En esta actividad, trabajar√°s guiado por **Luis**, nuestro Analista de BI, con una planilla de Google Sheets que registra la temperatura corporal de un grupo de personas durante 10 d√≠as.  \n",
        "Debes realizar un examen preliminar para identificar datos problem√°ticos, como duplicados y valores nulos.  \n",
        "Esta pr√°ctica te ayudar√° a dar los pasos previos a la limpieza de datos, un componente vital en cualquier proyecto de an√°lisis.\n",
        "\n",
        "### Consigna\n",
        "1. Crear un DataFrame a partir de la planilla de c√°lculo y efectuar un examen preliminar.\n",
        "2. Identificar los datos:\n",
        "   - Duplicados\n",
        "   - Nulos\n",
        "3. Analizar cu√°l ser√≠a el mejor tratamiento para los datos an√≥malos (fuera de rango) y nulos.\n"
      ],
      "metadata": {
        "id": "pi5KsL0DEEws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from google.colab import files\n",
        "\n",
        "# ===============================\n",
        "# Funci√≥n: Generar y descargar dataset simulado\n",
        "# ===============================\n",
        "def generar_y_descargar_dataset(nombre_archivo=\"dataset_simulado.xlsx\", n_filas=150):\n",
        "    \"\"\"\n",
        "    Genera un dataset simulado con datos de temperatura, nulos, duplicados y anomal√≠as,\n",
        "    guarda un archivo Excel y permite descargarlo directamente en Colab.\n",
        "\n",
        "    Par√°metros:\n",
        "    nombre_archivo : str : nombre del archivo Excel a generar (por defecto 'dataset_simulado.xlsx')\n",
        "    n_filas : int : cantidad de filas que tendr√° el dataset (por defecto 150)\n",
        "\n",
        "    Retorna:\n",
        "    str : nombre del archivo Excel generado\n",
        "    \"\"\"\n",
        "    np.random.seed(42)\n",
        "\n",
        "    # Columnas del dataset\n",
        "    columnas = [\"ID\", \"Paciente\", \"Dia\", \"Temperatura\", \"Observaciones\"]\n",
        "\n",
        "    # Generar datos simulados\n",
        "    ids = [f\"P{str(i).zfill(3)}\" for i in range(1, n_filas+1)]\n",
        "    pacientes = [f\"Paciente_{random.randint(1, 50)}\" for _ in range(n_filas)]\n",
        "    dias = [random.randint(1, 10) for _ in range(n_filas)]\n",
        "    temperaturas = np.random.normal(loc=36.6, scale=0.5, size=n_filas)\n",
        "\n",
        "    # Insertar valores nulos aleatorios\n",
        "    for _ in range(int(0.05*n_filas)):\n",
        "        idx = random.randint(0, n_filas-1)\n",
        "        temperaturas[idx] = np.nan\n",
        "\n",
        "    # Insertar anomal√≠as (temperaturas fuera de rango)\n",
        "    for _ in range(int(0.05*n_filas)):\n",
        "        idx = random.randint(0, n_filas-1)\n",
        "        temperaturas[idx] = random.uniform(39, 42)\n",
        "\n",
        "    observaciones = [\"\"]*n_filas\n",
        "\n",
        "    # Crear DataFrame\n",
        "    df = pd.DataFrame({\n",
        "        \"ID\": ids,\n",
        "        \"Paciente\": pacientes,\n",
        "        \"Dia\": dias,\n",
        "        \"Temperatura\": temperaturas,\n",
        "        \"Observaciones\": observaciones\n",
        "    })\n",
        "\n",
        "    # Insertar duplicados aleatorios\n",
        "    for _ in range(int(0.05*n_filas)):\n",
        "        dup = df.sample(1)\n",
        "        df = pd.concat([df, dup], ignore_index=True)\n",
        "\n",
        "    # Guardar a Excel\n",
        "    df.to_excel(nombre_archivo, index=False)\n",
        "\n",
        "    # Descargar el archivo en Colab\n",
        "    files.download(nombre_archivo)\n",
        "\n",
        "    print(f\"Archivo Excel generado y listo para descargar: {nombre_archivo}\")\n",
        "    return nombre_archivo\n",
        "\n",
        "#Caso de uso\n",
        "archivo = generar_y_descargar_dataset()\n"
      ],
      "metadata": {
        "id": "C-bhpF12Gnss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# 1. Subir el archivo Excel\n",
        "uploaded = files.upload()\n",
        "nombre_archivo = list(uploaded.keys())[0]\n",
        "\n",
        "# 2. Cargar el Excel en un DataFrame\n",
        "df = pd.read_excel(nombre_archivo, engine='openpyxl')\n",
        "print(\"Primeras filas del dataset:\")\n",
        "display(df.head())\n",
        "\n",
        "# 3. Resumen de nulos y duplicados\n",
        "print(\"Valores nulos por columna:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(\"\\nCantidad de filas duplicadas:\", df.duplicated().sum())\n",
        "\n",
        "# 4. Generar tabla de decisiones autom√°ticamente\n",
        "def analizar_actividad2(df):\n",
        "    \"\"\"\n",
        "    Creo la tabla de decisiones indicando qu√© hacer con nulos, an√≥malos y duplicados\n",
        "    seg√∫n los contextos de la actividad.\n",
        "    \"\"\"\n",
        "    # Contextos y tipos de dato seg√∫n la consigna\n",
        "    tabla = pd.DataFrame({\n",
        "        \"Contexto\": [\n",
        "            \"Estudio estad√≠stico\",\n",
        "            \"Estudio estad√≠stico\",\n",
        "            \"Seguimiento de un paciente\",\n",
        "            \"Seguimiento de un paciente\",\n",
        "            \"Detecci√≥n de casos de contagio\"\n",
        "        ],\n",
        "        \"Tipo de dato\": [\"an√≥malos\", \"nulos\", \"an√≥malos\", \"nulos\", \"an√≥malos\"],\n",
        "        \"Ignorar\": [\"\", \"\", \"\", \"\", \"\"],\n",
        "        \"Eliminar\": [\"\", \"\", \"\", \"\", \"\"],\n",
        "        \"Reemplazar\": [\"\", \"\", \"\", \"\", \"\"],\n",
        "        \"Analizar\": [\"\", \"\", \"\", \"\", \"\"]\n",
        "    })\n",
        "\n",
        "    # Llenar la tabla seg√∫n las reglas\n",
        "    for i, row in tabla.iterrows():\n",
        "        # Revisar nulos en el DataFrame\n",
        "        if row[\"Tipo de dato\"] == \"nulos\":\n",
        "            # Marcar reemplazar si hay nulos en el dataset\n",
        "            if df.isnull().sum().sum() > 0:\n",
        "                tabla.at[i, \"Reemplazar\"] = \"‚úîÔ∏è\"\n",
        "        # Revisar anomal√≠as (simuladas como valores fuera de rango)\n",
        "        if row[\"Tipo de dato\"] == \"an√≥malos\":\n",
        "            tabla.at[i, \"Analizar\"] = \"‚úîÔ∏è\"\n",
        "            # Marcar eliminar si hay duplicados\n",
        "            if df.duplicated().sum() > 0:\n",
        "                tabla.at[i, \"Eliminar\"] = \"‚úîÔ∏è\"\n",
        "\n",
        "    return tabla\n",
        "\n",
        "# Ejecuto la funci√≥n y mostrar la tabla\n",
        "tabla_decisiones = analizar_actividad2(df)\n",
        "print(\"Tabla de decisiones final:\")\n",
        "display(tabla_decisiones)\n",
        "\n",
        "# Guardo la tabla de decisiones a Excel\n",
        "tabla_decisiones.to_excel(\"tabla_decisiones_actividad2_final.xlsx\", index=False)\n",
        "print(\"Tabla guardada como 'tabla_decisiones_actividad2_final.xlsx'. Se puede descargar.üòâ\")\n"
      ],
      "metadata": {
        "id": "IZzaP-zGJZQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# 1. Subir archivo Excel\n",
        "uploaded = files.upload()\n",
        "nombre_archivo = list(uploaded.keys())[0]\n",
        "\n",
        "# 2. Cargo Excel en un DataFrame\n",
        "df = pd.read_excel(nombre_archivo, engine='openpyxl')\n",
        "print(\"Primeras filas del dataset:\")\n",
        "display(df.head())\n",
        "\n",
        "# 3. Resumen de nulos y duplicados\n",
        "print(\"Valores nulos por columna:\")\n",
        "display(df.isnull().sum())\n",
        "print(\"Cantidad de filas duplicadas:\", df.duplicated().sum())\n",
        "\n",
        "# 4. Funci√≥n para detectar anomal√≠as solo en Temperatura\n",
        "def detectar_anomalias_temperatura(df):\n",
        "    # Considero anomal√≠a si temperatura <35 o >42 (hipotermia - hipertermia)\n",
        "    anomalias = df[(df['Temperatura'] < 35) | (df['Temperatura'] > 42)]\n",
        "    return anomalias\n",
        "\n",
        "# 5. Funci√≥n para generar tabla de decisiones\n",
        "def analizar_actividad2_preciso(df):\n",
        "    tabla = pd.DataFrame({\n",
        "        \"Contexto\": [\n",
        "            \"Estudio estad√≠stico\",\n",
        "            \"Estudio estad√≠stico\",\n",
        "            \"Seguimiento de un paciente\",\n",
        "            \"Seguimiento de un paciente\",\n",
        "            \"Detecci√≥n de casos de contagio\"\n",
        "        ],\n",
        "        \"Tipo de dato\": [\"an√≥malos\", \"nulos\", \"an√≥malos\", \"nulos\", \"an√≥malos\"],\n",
        "        \"Ignorar\": [\"\", \"\", \"\", \"\", \"\"],\n",
        "        \"Eliminar\": [\"\", \"\", \"\", \"\", \"\"],\n",
        "        \"Reemplazar\": [\"\", \"\", \"\", \"\", \"\"],\n",
        "        \"Analizar\": [\"\", \"\", \"\", \"\", \"\"]\n",
        "    })\n",
        "\n",
        "    # Anomal√≠as en Temperatura\n",
        "    anomal√≠as = detectar_anomalias_temperatura(df)\n",
        "    total_anom = anomal√≠as.shape[0]\n",
        "\n",
        "    # Nulos\n",
        "    total_nulos = df.isnull().sum().sum()\n",
        "\n",
        "    # Duplicados\n",
        "    total_duplicados = df.duplicated().sum()\n",
        "\n",
        "    # Llenar la tabla\n",
        "    for i, row in tabla.iterrows():\n",
        "        if row[\"Tipo de dato\"] == \"nulos\" and total_nulos > 0:\n",
        "            tabla.at[i, \"Reemplazar\"] = f\"‚úîÔ∏è ({total_nulos})\"\n",
        "        if row[\"Tipo de dato\"] == \"an√≥malos\" and total_anom > 0:\n",
        "            tabla.at[i, \"Analizar\"] = f\"‚úîÔ∏è ({total_anom})\"\n",
        "        if total_duplicados > 0:\n",
        "            tabla.at[i, \"Eliminar\"] = f\"‚úîÔ∏è ({total_duplicados})\"\n",
        "\n",
        "    return tabla\n",
        "\n",
        "# 6. Mostrar tabla consolidada\n",
        "tabla_decisiones = analizar_actividad2_preciso(df)\n",
        "print(\"Tabla de decisiones final (conteo real):\")\n",
        "display(tabla_decisiones)\n",
        "\n",
        "# 7. Guardar la tabla final\n",
        "tabla_decisiones.to_excel(\"tabla_decisiones_actividad2_preciso.xlsx\", index=False)\n",
        "print(\"Tabla guardada como 'tabla_decisiones_actividad2_preciso.xlsx'. Descargar. üêç\")\n"
      ],
      "metadata": {
        "id": "P3093tYcN-3h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}